{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.21.6)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-12.0.1\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from wordcloud) (3.5.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from wordcloud) (1.21.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (4.37.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n",
      "Collecting gensim\n",
      "  Using cached gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.21.6)\n",
      "Collecting wrapt\n",
      "  Using cached wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Installing collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.2.0 smart-open-7.0.4 wrapt-1.16.0\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.8.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.62.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.34.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.9.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.1)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.7\n",
      "    Uninstalling protobuf-4.21.7:\n",
      "      Successfully uninstalled protobuf-4.21.7\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.3 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.29.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.62.2 keras-2.11.0 libclang-18.1.1 markdown-3.4.4 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 werkzeug-2.2.3\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2024.4.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.4.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.4.16\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install wordcloud\n",
    "!pip install gensim\n",
    "!pip install tensorflow\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, make_scorer, f1_score\n",
    "import time\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import base64\n",
    "import re\n",
    "\n",
    "def decode_base64(word):\n",
    "    try:\n",
    "        return base64.b64decode(word).decode(\"utf-8\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_session(full_session):\n",
    "    words = []\n",
    "    for word in re.split(r\"\\n|;|,|/|-|\\||=|$|>|<|$|:|{|}|\\(|\\)| \", full_session):\n",
    "        if word.startswith('\"') or word.endswith('\"'):\n",
    "            # remove the quotation mark at the start and at the end of the word\n",
    "            word = word[1:-1]\n",
    "        elif len(word) == 1 and word in string.punctuation:\n",
    "            # remove that punctuation\n",
    "            word = None\n",
    "        words.append(word)\n",
    "    return list(filter(None, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_session(full_session):\n",
    "    new_full_session = []\n",
    "    for session_chunck in full_session.split(\";\"):\n",
    "        if \"base64 --decode\" in session_chunck or \"echo\" in session_chunck:\n",
    "            for word in session_chunck.split(\"\\\"\"):\n",
    "                decode = decode_base64(word)\n",
    "                if decode:\n",
    "                    new_full_session.append(decode)\n",
    "        else:\n",
    "            new_full_session.append(session_chunck)\n",
    "    return split_session(\"\".join(new_full_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying explode and then taking 10% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_parquet('ssh_attacks.parquet')\n",
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df.explode(\"Set_Fingerprint\").reset_index()\n",
    "df_exploded = df_exploded.drop(columns=['index'])\n",
    "\n",
    "label_counts = df_exploded['Set_Fingerprint'].value_counts()\n",
    "label_counts\n",
    "\n",
    "df_persistence = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Persistence\"].sample(frac=0.2).copy()\n",
    "df_discovery = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Discovery\"].sample(frac=0.2).copy()\n",
    "df_defenseEvasion = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Defense Evasion\"].sample(frac=0.2).copy()\n",
    "df_execution = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Execution\"].sample(frac=0.2).copy()\n",
    "df_impact = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Impact\"].sample(frac=1).copy()\n",
    "df_other = df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Other\"].sample(frac=1).copy()\n",
    "df_harmless= df_exploded[df_exploded[\"Set_Fingerprint\"] == \"Harmless\"].sample(frac=0.35).copy()\n",
    "\n",
    "\n",
    "df_subset = pd.concat([df_persistence, df_discovery, df_defenseEvasion, df_execution, df_impact, df_other, df_harmless], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discovery          232145\n",
       "Persistence        211295\n",
       "Execution           92927\n",
       "Defense Evasion     18999\n",
       "Harmless             2206\n",
       "Other                 327\n",
       "Impact                 27\n",
       "Name: Set_Fingerprint, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['first_timestamp'] = pd.to_datetime(df_subset['first_timestamp'])\n",
    "df_subset[\"full_session\"] = df_subset[\"full_session\"].apply(lambda x: clean_session(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        session_id                                       full_session  \\\n",
      "0                0  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
      "1                1  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
      "2                2  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
      "3                3  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
      "4                4  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
      "...            ...                                                ...   \n",
      "233030      233042  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
      "233031      233043  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
      "233032      233044  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
      "233033      233045  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
      "233034      233046  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
      "\n",
      "                         first_timestamp               Set_Fingerprint  \n",
      "0       2019-06-04 09:45:11.151186+00:00  [Defense Evasion, Discovery]  \n",
      "1       2019-06-04 09:45:50.396610+00:00  [Defense Evasion, Discovery]  \n",
      "2       2019-06-04 09:54:41.863315+00:00  [Defense Evasion, Discovery]  \n",
      "3       2019-06-04 10:22:14.623875+00:00  [Defense Evasion, Discovery]  \n",
      "4       2019-06-04 10:37:19.725874+00:00  [Defense Evasion, Discovery]  \n",
      "...                                  ...                           ...  \n",
      "233030  2020-02-29 23:47:28.217237+00:00      [Discovery, Persistence]  \n",
      "233031  2020-02-29 23:49:01.009046+00:00      [Discovery, Persistence]  \n",
      "233032  2020-02-29 23:56:18.827281+00:00      [Discovery, Persistence]  \n",
      "233033  2020-02-29 23:56:56.263104+00:00      [Discovery, Persistence]  \n",
      "233034  2020-02-29 23:59:22.199490+00:00      [Discovery, Persistence]  \n",
      "\n",
      "[233035 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_parquet(\"ssh_attacks_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features.txt\", \"r\") as f:\n",
    "    vocabuary = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"df_features_bow.parquet\"):\n",
    "    count_vectorizer = CountVectorizer(vocabulary=vocabuary)\n",
    "    bow = count_vectorizer.fit_transform(df_subset[\"full_session\"].apply(lambda x : \" \".join(x)))\n",
    "    df_bow = pd.DataFrame(bow.toarray(), index=df_subset.index, columns = list(count_vectorizer.vocabulary_.keys()))\n",
    "    for feature in df_bow.columns:\n",
    "        df_bow[feature] = normalize(df_bow[feature].values.reshape(-1,1), norm=\"l2\", axis=0)\n",
    "    df_bow = pd.concat([df_subset, df_bow], axis=1)\n",
    "    df_features_bow = df_bow.drop(columns=[\"session_id\", \"full_session\", \"first_timestamp\", \"Set_Fingerprint\"])\n",
    "    df_features_bow.to_parquet(\"df_features_bow.parquet\")\n",
    "else:\n",
    "    df_features_bow = pd.read_parquet(\"df_features_bow.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"df_features_tfidf.parquet\"):\n",
    "    tfidf_vectorizer = TfidfVectorizer(vocabulary=vocabuary)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(df_subset[\"full_session\"].apply(lambda x : \" \".join(x)))\n",
    "    df_tfidf = pd.DataFrame(tfidf.toarray(), index=df_subset.index, columns = list(tfidf_vectorizer.vocabulary_.keys()))\n",
    "    df_tfidf = pd.concat([df_subset, df_tfidf], axis=1)\n",
    "    df_features_tfidf = df_tfidf.drop(columns=[\"session_id\", \"full_session\", \"first_timestamp\", \"Set_Fingerprint\"])\n",
    "    df_features_tfidf.to_parquet(\"df_features_tfidf.parquet\")\n",
    "else:\n",
    "    df_features_tfidf = pd.read_parquet(\"df_features_tfidf.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isfile(\"ssh_attacks_decoded_splitted.parquet\"):\n",
    "#     raise Exception(\"You should run the preprocessing file\")\n",
    "    \n",
    "# df = pd.read_parquet(\"ssh_attacks_decoded_splitted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not (os.path.isfile(\"df_features_bow.parquet\") and os.path.isfile(\"df_features_tfidf.parquet\")):\n",
    "#     raise Exception(\"You should run the section 1 before\")\n",
    "    \n",
    "# df_features_bow = pd.read_parquet(\"df_features_bow.parquet\")\n",
    "# df_features_tfidf = pd.read_parquet(\"df_features_tfidf.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>alpine</th>\n",
       "      <th>apt</th>\n",
       "      <th>ar</th>\n",
       "      <th>ash</th>\n",
       "      <th>awk</th>\n",
       "      <th>base64</th>\n",
       "      <th>bash</th>\n",
       "      <th>bin</th>\n",
       "      <th>bs</th>\n",
       "      <th>...</th>\n",
       "      <th>tmp</th>\n",
       "      <th>top</th>\n",
       "      <th>tsm</th>\n",
       "      <th>udp</th>\n",
       "      <th>uname</th>\n",
       "      <th>unix</th>\n",
       "      <th>var</th>\n",
       "      <th>vim</th>\n",
       "      <th>wget</th>\n",
       "      <th>which</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.054358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509334</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.255038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080367</td>\n",
       "      <td>0.074653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249821</td>\n",
       "      <td>0.049976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150460</td>\n",
       "      <td>0.321684</td>\n",
       "      <td>0.150111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170178</td>\n",
       "      <td>0.100319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.054358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509334</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.255038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495108</td>\n",
       "      <td>0.035373</td>\n",
       "      <td>0.115148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106496</td>\n",
       "      <td>0.512302</td>\n",
       "      <td>0.247915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112199 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ab  alpine  apt   ar  ash       awk  base64      bash       bin   bs  \\\n",
       "0       0.0     0.0  0.0  0.0  0.0  0.073036     0.0  0.058519  0.054358  0.0   \n",
       "1       0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000  0.000000  0.0   \n",
       "2       0.0     0.0  0.0  0.0  0.0  0.100305     0.0  0.080367  0.074653  0.0   \n",
       "3       0.0     0.0  0.0  0.0  0.0  0.073036     0.0  0.058519  0.054358  0.0   \n",
       "4       0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000  0.000000  0.0   \n",
       "...     ...     ...  ...  ...  ...       ...     ...       ...       ...  ...   \n",
       "112194  0.0     0.0  0.0  0.0  0.0  0.070996     0.0  0.056884  0.052839  0.0   \n",
       "112195  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000  0.000000  0.0   \n",
       "112196  0.0     0.0  0.0  0.0  0.0  0.000000     0.0  0.000000  0.000000  0.0   \n",
       "112197  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000  0.000000  0.0   \n",
       "112198  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "        ...       tmp       top       tsm  udp     uname      unix       var  \\\n",
       "0       ...  0.509334  0.036390  0.118457  0.0  0.109556  0.468464  0.255038   \n",
       "1       ...  0.265313  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "2       ...  0.249821  0.049976  0.000000  0.0  0.150460  0.321684  0.150111   \n",
       "3       ...  0.509334  0.036390  0.118457  0.0  0.109556  0.468464  0.255038   \n",
       "4       ...  0.265313  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "...     ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "112194  ...  0.495108  0.035373  0.115148  0.0  0.106496  0.512302  0.247915   \n",
       "112195  ...  0.265313  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "112196  ...  0.168183  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "112197  ...  0.265313  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "112198  ...  0.265313  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "\n",
       "        vim      wget     which  \n",
       "0       0.0  0.000000  0.073047  \n",
       "1       0.0  0.000000  0.088784  \n",
       "2       0.0  0.170178  0.100319  \n",
       "3       0.0  0.000000  0.073047  \n",
       "4       0.0  0.000000  0.088784  \n",
       "...     ...       ...       ...  \n",
       "112194  0.0  0.000000  0.071006  \n",
       "112195  0.0  0.000000  0.088784  \n",
       "112196  0.0  0.000000  0.000000  \n",
       "112197  0.0  0.000000  0.088784  \n",
       "112198  0.0  0.000000  0.088784  \n",
       "\n",
       "[112199 rows x 71 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        session_id                                       full_session  \\\n",
      "0            82694  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "1           126467  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "2             3971  [cd, var, tmp, #!, bin, bash, cd, tmp, rm, rf,...   \n",
      "3            86173  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "4           209498  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "...            ...                                                ...   \n",
      "112194       14437  [cat, proc, cpuinfo, grep, name, wc, l, Enter,...   \n",
      "112195       95221  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "112196       11785                            [scp, t, tmp, S7rKjnXk]   \n",
      "112197       53342  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "112198      152010  [cat, proc, cpuinfo, grep, name, wc, l, rm, rf...   \n",
      "\n",
      "                        first_timestamp Set_Fingerprint   ab  alpine  apt  \\\n",
      "0      2019-11-13 16:07:17.558060+00:00     Persistence  0.0     0.0  0.0   \n",
      "1      2019-12-06 02:16:00.317672+00:00     Persistence  0.0     0.0  0.0   \n",
      "2      2019-06-27 23:23:51.534859+00:00     Persistence  0.0     0.0  0.0   \n",
      "3      2019-11-15 19:47:41.871092+00:00     Persistence  0.0     0.0  0.0   \n",
      "4      2020-02-01 03:58:46.540737+00:00     Persistence  0.0     0.0  0.0   \n",
      "...                                 ...             ...  ...     ...  ...   \n",
      "112194 2019-09-10 00:57:27.235016+00:00        Harmless  0.0     0.0  0.0   \n",
      "112195 2019-11-21 19:15:04.672886+00:00        Harmless  0.0     0.0  0.0   \n",
      "112196 2019-08-27 09:52:44.189888+00:00        Harmless  0.0     0.0  0.0   \n",
      "112197 2019-10-25 13:07:28.856084+00:00        Harmless  0.0     0.0  0.0   \n",
      "112198 2019-12-10 20:14:39.477467+00:00        Harmless  0.0     0.0  0.0   \n",
      "\n",
      "         ar  ash       awk  ...       tmp       top       tsm  udp     uname  \\\n",
      "0       0.0  0.0  0.073036  ...  0.509334  0.036390  0.118457  0.0  0.109556   \n",
      "1       0.0  0.0  0.177542  ...  0.265313  0.088459  0.000000  0.0  0.266317   \n",
      "2       0.0  0.0  0.100305  ...  0.249821  0.049976  0.000000  0.0  0.150460   \n",
      "3       0.0  0.0  0.073036  ...  0.509334  0.036390  0.118457  0.0  0.109556   \n",
      "4       0.0  0.0  0.177542  ...  0.265313  0.088459  0.000000  0.0  0.266317   \n",
      "...     ...  ...       ...  ...       ...       ...       ...  ...       ...   \n",
      "112194  0.0  0.0  0.070996  ...  0.495108  0.035373  0.115148  0.0  0.106496   \n",
      "112195  0.0  0.0  0.177542  ...  0.265313  0.088459  0.000000  0.0  0.266317   \n",
      "112196  0.0  0.0  0.000000  ...  0.168183  0.000000  0.000000  0.0  0.000000   \n",
      "112197  0.0  0.0  0.177542  ...  0.265313  0.088459  0.000000  0.0  0.266317   \n",
      "112198  0.0  0.0  0.177542  ...  0.265313  0.088459  0.000000  0.0  0.266317   \n",
      "\n",
      "            unix       var  vim      wget     which  \n",
      "0       0.468464  0.255038  0.0  0.000000  0.073047  \n",
      "1       0.000000  0.265699  0.0  0.000000  0.088784  \n",
      "2       0.321684  0.150111  0.0  0.170178  0.100319  \n",
      "3       0.468464  0.255038  0.0  0.000000  0.073047  \n",
      "4       0.000000  0.265699  0.0  0.000000  0.088784  \n",
      "...          ...       ...  ...       ...       ...  \n",
      "112194  0.512302  0.247915  0.0  0.000000  0.071006  \n",
      "112195  0.000000  0.265699  0.0  0.000000  0.088784  \n",
      "112196  0.000000  0.000000  0.0  0.000000  0.000000  \n",
      "112197  0.000000  0.265699  0.0  0.000000  0.088784  \n",
      "112198  0.000000  0.265699  0.0  0.000000  0.088784  \n",
      "\n",
      "[112199 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.concat([df_subset,df_features_tfidf], axis=1)\n",
    "print(df_final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore this part-- it was just for test puposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I was trying to add some other features like timestamp and id_Session, standardizing them and \n",
    "#then adding them to the final dataser but it seems that the result gets worse with these new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# standardized the timestamp column and session_id\n",
    "df_final['first_timestamp'] = pd.to_datetime(df_final['first_timestamp'])\n",
    "df_final['first_timestamp_num'] = df_final['first_timestamp'].view(int) // 10**9  # Convert to Unix timestamps (seconds)\n",
    "df_final['first_timestamp_num']\n",
    "\n",
    "# Drop the original timestamp column \n",
    "df_final.drop(columns=['first_timestamp'], inplace=True)\n",
    "\n",
    "# Scaling the numerical representation using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_final[['session_id', 'first_timestamp_num']] = scaler.fit_transform(df_final[['session_id','first_timestamp_num']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### end of part to be ignored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=4>Section 2 – Supervised Learning – Classification<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"text-align: justify\"> Classify the tactics of an attack session, based on the used words in the text and also possibly on time. Notice that each session have multiple labels. Hence you can decompose the problem into multiple binary classification problems. For each attack session, you have to solve the 7 binary classification problem, one for each possible label {'Persistence', 'Discovery', 'Defense Evasion', 'Execution', 'Impact', 'Other', 'Harmless'}. </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Perform a split to segment the dataset into training and test dataset. If you want to standardize your dataset, fit the scaler on training set and transforming both training and test. Notice that the sklearn implementation of tf-idf already performs the standardization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(columns=['Set_Fingerprint','full_session'])\n",
    "y = df_final[['Set_Fingerprint']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ab</th>\n",
       "      <th>alpine</th>\n",
       "      <th>apt</th>\n",
       "      <th>ar</th>\n",
       "      <th>ash</th>\n",
       "      <th>awk</th>\n",
       "      <th>base64</th>\n",
       "      <th>bash</th>\n",
       "      <th>bin</th>\n",
       "      <th>...</th>\n",
       "      <th>top</th>\n",
       "      <th>tsm</th>\n",
       "      <th>udp</th>\n",
       "      <th>uname</th>\n",
       "      <th>unix</th>\n",
       "      <th>var</th>\n",
       "      <th>vim</th>\n",
       "      <th>wget</th>\n",
       "      <th>which</th>\n",
       "      <th>first_timestamp_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.403458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.054358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.255038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>-0.173066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>0.292328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.605141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080367</td>\n",
       "      <td>0.074653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150460</td>\n",
       "      <td>0.321684</td>\n",
       "      <td>0.150111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170178</td>\n",
       "      <td>0.100319</td>\n",
       "      <td>-3.051787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.350352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.054358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.255038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>-0.128379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.532166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>1.476873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112194</th>\n",
       "      <td>-1.445380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035373</td>\n",
       "      <td>0.115148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106496</td>\n",
       "      <td>0.512302</td>\n",
       "      <td>0.247915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>-1.514532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112195</th>\n",
       "      <td>-0.212237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>-0.004316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112196</th>\n",
       "      <td>-1.485862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.797393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112197</th>\n",
       "      <td>-0.851507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>-0.570013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112198</th>\n",
       "      <td>0.654630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>0.390897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112199 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id   ab  alpine  apt   ar  ash       awk  base64      bash  \\\n",
       "0        -0.403458  0.0     0.0  0.0  0.0  0.0  0.073036     0.0  0.058519   \n",
       "1         0.264723  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000   \n",
       "2        -1.605141  0.0     0.0  0.0  0.0  0.0  0.100305     0.0  0.080367   \n",
       "3        -0.350352  0.0     0.0  0.0  0.0  0.0  0.073036     0.0  0.058519   \n",
       "4         1.532166  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000   \n",
       "...            ...  ...     ...  ...  ...  ...       ...     ...       ...   \n",
       "112194   -1.445380  0.0     0.0  0.0  0.0  0.0  0.070996     0.0  0.056884   \n",
       "112195   -0.212237  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000   \n",
       "112196   -1.485862  0.0     0.0  0.0  0.0  0.0  0.000000     0.0  0.000000   \n",
       "112197   -0.851507  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000   \n",
       "112198    0.654630  0.0     0.0  0.0  0.0  0.0  0.177542     0.0  0.000000   \n",
       "\n",
       "             bin  ...       top       tsm  udp     uname      unix       var  \\\n",
       "0       0.054358  ...  0.036390  0.118457  0.0  0.109556  0.468464  0.255038   \n",
       "1       0.000000  ...  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "2       0.074653  ...  0.049976  0.000000  0.0  0.150460  0.321684  0.150111   \n",
       "3       0.054358  ...  0.036390  0.118457  0.0  0.109556  0.468464  0.255038   \n",
       "4       0.000000  ...  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "...          ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "112194  0.052839  ...  0.035373  0.115148  0.0  0.106496  0.512302  0.247915   \n",
       "112195  0.000000  ...  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "112196  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "112197  0.000000  ...  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "112198  0.000000  ...  0.088459  0.000000  0.0  0.266317  0.000000  0.265699   \n",
       "\n",
       "        vim      wget     which  first_timestamp_num  \n",
       "0       0.0  0.000000  0.073047            -0.173066  \n",
       "1       0.0  0.000000  0.088784             0.292328  \n",
       "2       0.0  0.170178  0.100319            -3.051787  \n",
       "3       0.0  0.000000  0.073047            -0.128379  \n",
       "4       0.0  0.000000  0.088784             1.476873  \n",
       "...     ...       ...       ...                  ...  \n",
       "112194  0.0  0.000000  0.071006            -1.514532  \n",
       "112195  0.0  0.000000  0.088784            -0.004316  \n",
       "112196  0.0  0.000000  0.000000            -1.797393  \n",
       "112197  0.0  0.000000  0.088784            -0.570013  \n",
       "112198  0.0  0.000000  0.088784             0.390897  \n",
       "\n",
       "[112199 rows x 73 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of trainning set is: 78539\n",
      "The size of test set is: 33660\n"
     ]
    }
   ],
   "source": [
    "print('The size of trainning set is:', len(X_train))\n",
    "print('The size of test set is:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "##### Standardization of the Numerical Features\n",
    "\n",
    "As the TF-IDF pre-processing was applied previously to all the sessions, the data considered as features was already standardized. \n",
    "\n",
    "##### Standardization of the Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "# y_train_mlb = mlb.fit_transform(y_train)\n",
    "# y_test_mlb = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_encoded = hot_encoder.fit_transform(y_train).toarray()\n",
    "y_test_encoded = hot_encoder.transform(y_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Techniques** \n",
    "<br>\n",
    "<div style=\"text-align: justify\"> A <b>MultiLabelBinarizer</b> is a transformer that is used for multi-label classification problems, in order to handle the cases where each sample belongs to multiple classes simultaneously. The purpose of MultiLabelBinarizer is to convert a collection of sequences of labels into a binary matrix format. The binary classification of each label in the 'Set_Fingerprint' column was performed by converting the multi-class label matrix into a binary matrix, where each column represents one of the possible classes and each row represents one instance. </div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"> <b>TF-IDF </b> (explain technique here) </div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"> MultiLabelBinarizer is used to handle categorical variables before fitting a model, as most machine learning algorithms can only handle numerical data.</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Choose at least 2 ML methods, and perform the model training, with default parameter\n",
    "configuration, evaluating the performance on both training and test set. Output the confusion\n",
    "matrix and classification report. Do you observe overfitting or under-fitting? Which model\n",
    "generates the best performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><left><b><font size=4> Random Forest (RF)<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Random Forest (RF) serves as a classification model that constructs a collection of decision trees (DT) using a randomly chosen subset of the given training set. The model aggregates the individual decisions made by each decision tree and combines their votes to make the ultimate prediction.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 55.77 seconds\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "st = time.time()\n",
    "rf.fit(X_train, y_train_encoded)\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print(f\"Time to train the model: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predictions = rf.predict(X_train)\n",
    "y_test_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the predicted labels back to their original format if necessary\n",
    "y_train_dec = hot_encoder.inverse_transform(y_train_encoded)\n",
    "\n",
    "# Generate a list of unique labels from both true and predicted labels\n",
    "# Get unique y_train_dec\n",
    "unique_labels = np.unique(y_train_dec)\n",
    "# Convert the unique labels to a list to be used in the classification report Target\n",
    "unique_labels_list = unique_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the 'Random Forest' model for the training set: 0.87\n",
      "Accuracy of the 'Random Forest' model for test set: 0.32\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the train data\n",
    "accuracy = rf.score(X_train, y_train_encoded)\n",
    "print(f\"Accuracy of the 'Random Forest' model for the training set: {accuracy:.2f}\")\n",
    "\n",
    "# Evaluate the model's performance on the test data\n",
    "accuracy = rf.score(X_test, y_test_encoded)\n",
    "print(f\"Accuracy of the 'Random Forest' model for test set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=3 >Classification Report<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defense Evasion</th>\n",
       "      <td>0.924735</td>\n",
       "      <td>0.920557</td>\n",
       "      <td>0.922642</td>\n",
       "      <td>2656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.882533</td>\n",
       "      <td>0.902378</td>\n",
       "      <td>32375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Execution</th>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.826640</td>\n",
       "      <td>0.864761</td>\n",
       "      <td>13123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmless</th>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.778612</td>\n",
       "      <td>0.865485</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.864629</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Persistence</th>\n",
       "      <td>0.923151</td>\n",
       "      <td>0.878150</td>\n",
       "      <td>0.900088</td>\n",
       "      <td>29602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.920452</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.895591</td>\n",
       "      <td>78539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.844718</td>\n",
       "      <td>0.879129</td>\n",
       "      <td>78539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.920450</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.895454</td>\n",
       "      <td>78539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>78539.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall  f1-score  support\n",
       "Defense Evasion   0.924735  0.920557  0.922642   2656.0\n",
       "Discovery         0.923137  0.882533  0.902378  32375.0\n",
       "Execution         0.906569  0.826640  0.864761  13123.0\n",
       "Harmless          0.974178  0.778612  0.865485    533.0\n",
       "Impact            1.000000  0.761905  0.864865     21.0\n",
       "Other             0.804878  0.864629  0.833684    229.0\n",
       "Persistence       0.923151  0.878150  0.900088  29602.0\n",
       "micro avg         0.920452  0.872038  0.895591  78539.0\n",
       "macro avg         0.922378  0.844718  0.879129  78539.0\n",
       "weighted avg      0.920450  0.872038  0.895454  78539.0\n",
       "samples avg       0.872038  0.872038  0.872038  78539.0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_training = classification_report(y_train_encoded, y_train_predictions, target_names=unique_labels_list, output_dict=True, zero_division=0)\n",
    "df_report_training = pd.DataFrame(report_training).transpose()\n",
    "df_report_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Set (Test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defense Evasion</th>\n",
       "      <td>0.399314</td>\n",
       "      <td>0.407343</td>\n",
       "      <td>0.403289</td>\n",
       "      <td>1144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.344386</td>\n",
       "      <td>0.351898</td>\n",
       "      <td>14054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Execution</th>\n",
       "      <td>0.240906</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.236162</td>\n",
       "      <td>5462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmless</th>\n",
       "      <td>0.159794</td>\n",
       "      <td>0.129707</td>\n",
       "      <td>0.143187</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Persistence</th>\n",
       "      <td>0.344013</td>\n",
       "      <td>0.330015</td>\n",
       "      <td>0.336868</td>\n",
       "      <td>12657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.335138</td>\n",
       "      <td>0.321747</td>\n",
       "      <td>0.328306</td>\n",
       "      <td>33660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.354280</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.316288</td>\n",
       "      <td>33660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.334834</td>\n",
       "      <td>0.321747</td>\n",
       "      <td>0.328122</td>\n",
       "      <td>33660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.321747</td>\n",
       "      <td>0.321747</td>\n",
       "      <td>0.321747</td>\n",
       "      <td>33660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall  f1-score  support\n",
       "Defense Evasion   0.399314  0.407343  0.403289   1144.0\n",
       "Discovery         0.359744  0.344386  0.351898  14054.0\n",
       "Execution         0.240906  0.231600  0.236162   5462.0\n",
       "Harmless          0.159794  0.129707  0.143187    239.0\n",
       "Impact            0.500000  0.166667  0.250000      6.0\n",
       "Other             0.476190  0.510204  0.492611     98.0\n",
       "Persistence       0.344013  0.330015  0.336868  12657.0\n",
       "micro avg         0.335138  0.321747  0.328306  33660.0\n",
       "macro avg         0.354280  0.302846  0.316288  33660.0\n",
       "weighted avg      0.334834  0.321747  0.328122  33660.0\n",
       "samples avg       0.321747  0.321747  0.321747  33660.0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance on test set\n",
    "report_test = classification_report(y_test_encoded, y_test_predictions, target_names=unique_labels_list,output_dict=True, zero_division=0)\n",
    "df_report_test = pd.DataFrame(report_test).transpose()\n",
    "df_report_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I only got to run up to this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=3> Confusion Matrix <b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf_train = multilabel_confusion_matrix(y_train_mlb, y_train_predictions)\n",
    "\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    print(f\"Confusion Matrix for '{label}':\")\n",
    "    print(confusion_rf_train[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.title(f\"Confusion Matrix for '{label}'\")\n",
    "    plt.imshow(confusion_rf_train[i], cmap='Blues', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(np.arange(2), ['Negative', 'Positive'])\n",
    "    plt.yticks(np.arange(2), ['Negative', 'Positive'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf_test = multilabel_confusion_matrix(y_test_mlb, y_test_predictions)\n",
    "\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    print(f\"Confusion Matrix for '{label}':\")\n",
    "    print(confusion_rf_test[i], \"\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.title(f\"Confusion Matrix for '{label}' in Test Set\")\n",
    "    plt.imshow(confusion_rf_test[i], cmap='Oranges', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(np.arange(2), ['Negative', 'Positive'])\n",
    "    plt.yticks(np.arange(2), ['Negative', 'Positive'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=4>K-Nearest Neighbors (KNN)<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">K-Nearest Neighbors (KNN) operates as a supervised learning classifier that relies on the concept of proximity to perform classifications or predictions for individual data points. Its fundamental principle is grounded in the notion that similar data points tend to cluster together. In the context of classification tasks, KNN assigns a class label to a data point by considering the majority vote of its nearest neighbors. Put simply, it selects the label that is most prevalent among the neighboring data points in close proximity to the one being evaluated.</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "st = time.time()\n",
    "knn.fit(X_train, y_train_mlb)\n",
    "et = time.time()\n",
    "\n",
    "elapsed_time = et - st\n",
    "print(f\"Time to train the model: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = knn.predict(X_train) \n",
    "predictions_test = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = knn.score(X_train, y_train_mlb)\n",
    "print(f\"Accuracy of the k-NN model for the training set: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = knn.score(X_test, y_test_mlb)\n",
    "print(f\"Accuracy of the k-NN model for the test set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=3 >Classification Report<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for training set\n",
    "report_train_knn = classification_report(y_train_mlb, predictions_train, target_names=mlb.classes_, output_dict=True, zero_division=1)\n",
    "df_report_train = pd.DataFrame(report_train_knn).transpose()\n",
    "print(\"Classification Report for Trainning set:\")\n",
    "df_report_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for test set\n",
    "report_test_knn = classification_report(y_test_mlb, predictions_test, target_names=mlb.classes_, output_dict=True, zero_division=1)\n",
    "df_report_test_knn = pd.DataFrame(report_test_knn).transpose()\n",
    "print(\"Classification Report for Test set:\")\n",
    "df_report_test_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=3> Confusion Matrix <b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code presented below prints a series of confusion matrices for each class, displaying True-Positive (top-left), False-Negative (bottom-left), False-Positive (top-right), and True-Negative (bottom-right) counts.\n",
    "- True Positives (TP): Predicted correctly as positive.\n",
    "- False Positives (FP): Predicted as positive but actually negative.\n",
    "- False Negatives (FN): Predicted as negative but actually positive.\n",
    "- True Negatives (TN): Predicted correctly as negative.\n",
    "\n",
    "Each value in the confusion matrix represents the count of instances falling into these categories for a specific label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with a confusion matrix and classification report\n",
    "confusion_knn_test = multilabel_confusion_matrix(y_test_mlb, predictions_test)\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    print(f\"Confusion Matrix for {label}:\")\n",
    "    print(confusion_knn_test[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.title(f\"Confusion Matrix for '{label}'\")\n",
    "    plt.imshow(confusion_knn_test[i], cmap='Oranges', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(np.arange(2), ['Negative', 'Positive'])\n",
    "    plt.yticks(np.arange(2), ['Negative', 'Positive'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> To know whether the model is underfitting or overfitting, we must first define these two terms. <br>\n",
    "<div style=\"text-align: justify\"><br><b>Underfitting</b> occurs when a model is too simple to capture the underlying patterns in the training data, resulting in poor performance even on the training set.  One indicator used to identify this modelling error is to look at the results; if both training and validation/testing performance are poor, the model is considered to be underfitted.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"><b>Overfitting</b> occurs when a model not only learns the underlying patterns in the training data, but also captures noise and random fluctuations, causing it to perform poorly on new and unknown data. One indicator used to identify this modelling error is to look at the results, if the model performs well on training data but poorly on validation or test data, it is considered overfitted.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">Once these two terms have been defined, it is possible to move on to the results obtained for both models. It is important to mention that, for both tests performed with the different classifiers, the default parameters were used.</div><br>\n",
    "<div style=\"text-align: justify\">For the <b>Random Forest (RF)</b> case, the default parameter implied the number of estimators equal to 100, and the tree depth was set to <i>'None'</i>. On the other hand, for the <b>K-Nearest Neighbor (KNN)</b> classifier, the number of estimators was set to 5, the leaf size to 30 and the type of distance calculation was <i>'Euclidean distance'</i> (p=2), all default parameters of the classifier.</div><br>\n",
    "    \n",
    "<b> Random Forest (RF)</b>\n",
    "<div style=\"text-align: justify\"> In the classification report of the training and test sets, for most of the classes, accuracy, recall and F1 score are slightly lower in the test set compared to the training set. This was expected, as models tend to generalise slightly worse with unseen data. However, the drop in performance is not significant, which indicates that the model still performs well on the test set. Furthermore, the accuracy obtained for the training set was 99%, while 98% for the test set.<br><br>\n",
    "    \n",
    "<div style=\"text-align: justify\">As can be seen in the validation set report, the model was not able to correctly classify instances of the <i>'Impact'</i> class, performing very poorly (0%) on all precision, recall and F1 score metrics. This result could be due to the default parameters set to train the model.  Tree depth is one of the most important parameter for tuning the model, as it sets the stop condition that limits the number of splits or levels deep a decision tree can go.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">To enhance the classifier results, it is necessary to adjust the maximum depth of the decision trees when performing hyperparameter fitting for a random forest model. The <i>'weighted avg'</i> metric also showed a decrease in performance on the test set, indicating that the model does not perform as well on the test set across all classes, considering the distribution of classes. Overall, the performance metrics on the test set remain high, indicating that the overfitting is not critical. </div><br>\n",
    "\n",
    "<b> K-Nearest Neighbor (KNN)</b>\n",
    "\n",
    "<div style=\"text-align: justify\">On the other hand, the classification report obtained for the KNN classifier showed a small difference between the training set and the validation set, for the test set the values obtained for each of the metrics; accuracy, recall, f1-score, were slightly lower compared to the results obtained for the training set.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"> For the <i>'Impact'</i> class, the metrics derived in the training set were significantly lower compared to the validation set, for all metrics. This improvement in the accuracy, recall and f1-score parameters for the <i>'Impact'</i> class in the test set indicates that the model's predictions for this class are more accurate and reliable when evaluated with new, unseen data.  Producing a recall of 50%, which means, that the model only correctly predicted this class for 50% of the evaluated intents. </div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">The difference obtained in this class for the training and validation sets suggests that the model did not sufficiently fit the <i>'Impact'</i> class during training, and then after the selection of the nearest neighbour from the test set, the model adjusted its predictions to better capture the features of the <i>'Impact'</i> class. However, it is important to note that the KNN classifier does not fit the data, it does not learn from the model, it only calculates the distance to the nearest points and selects the class according to the majority result of the nearest neighbours.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"> In general, the observed results do not indicate underfitting or overfitting, in fact, the average accuracy obtained in the classification report was 99%, matching with the obtained in the calculated accuracy score (98% for both sets). The high values of the <i>'micro-average'</i> in both sets suggest a good overall performance of the model. While the <i>'macro-average'</i> values are higher only in the test set, indicating that the model performs better after calculating the Euclidean distance of each point.</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Tune the hyper-parameters of the models through cross-validation. How do performance vary?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Hyperparameters are settings that control the learning process of machine learning models. While the parameters are learned during the training process, the hyperparameters are set before the training starts. Therefore, in order to find the parameters that best fit the performance of the model, the GridSearch technique was applied. This technique applies all possible combinations of hyperparameters, resulting in a set of parameters that will improve the performance of the model.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "params = {'n_estimators': [3, 50, 100], 'max_depth': [100, 1000, 10000] } #'criterion' :['gini', 'entropy']}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "gs_rf = GridSearchCV(rf, param_grid = params, scoring='f1_macro', cv = 5, verbose = 1) \n",
    "# scoring='accuracy'\n",
    "# cv: that's the number of fold for the cross-validation\n",
    "# verbose: specifies the verbosity level of the GridSearchCV object. \n",
    "\n",
    "# Trainning the model\n",
    "st = time.time()\n",
    "gs_rf.fit(X_train, y_train_mlb)\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print(f\"Time to train the model: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = gs_rf.best_params_\n",
    "print(f\"The best combination of parameters the Grid Search has found is: {best_params_rf}\")\n",
    "print(\"Best F1-Score: {:.2f}\".format(gs_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask to the prof which graph we should use -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the f1 macro reached for each combination\n",
    "y = gs_rf.cv_results_[\"mean_test_score\"].tolist()\n",
    "x = [i for i in range (1, len(y)+1)]\n",
    "mean_test_score_df = pd.DataFrame()\n",
    "mean_test_score_df[\"f1_macro\"] = y\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x = mean_test_score_df.index, y = \"f1_macro\", data = mean_test_score_df, color='blue')\n",
    "\n",
    "# Add a title and labels to the plot\n",
    "plt.title('F1-macro Scores for Different Parameters')\n",
    "plt.xlabel('Combination')\n",
    "plt.ylabel('F1-macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = pd.DataFrame(gs_rf.cv_results_)\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a pivot table \n",
    "scores_rf = results_rf.pivot(index='param_max_depth', columns='param_n_estimators', values='mean_test_score')\n",
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(scores_rf, annot=True, cmap='viridis', fmt='.5g')\n",
    "plt.xlabel('param_max_depth')\n",
    "plt.ylabel('param_n_estimators')\n",
    "plt.title('Mean F1-Score over all folds for each combination of parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [5, 10, 20], 'leaf_size': [10, 70, 100]}        #'metric': ['euclidean', 'manhattan']} \n",
    "grid_search_knn = GridSearchCV(knn, params, scoring='f1_macro', cv = 5, verbose=1)\n",
    "# scoring = 'accuracy'\n",
    "\n",
    "st = time.time()\n",
    "grid_search_knn.fit(X_train, y_train_mlb)\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print(f\"Time to train the model: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_knn = grid_search_knn.best_params_\n",
    "print(f\"The best combination of parameters the Grid Search has found is: {best_params_knn}\")\n",
    "print(\"Best F1-Score: {:.2f}\".format(grid_search_knn.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aks to the prof which graph we should use --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the f1 macro reached for each combination\n",
    "y = grid_search_knn.cv_results_[\"mean_test_score\"].tolist()\n",
    "x = [i for i in range (1, len(y)+1)]\n",
    "mean_test_score_df = pd.DataFrame()\n",
    "mean_test_score_df[\"f1_macro\"] = y\n",
    "#print(mean_test_score_df)\n",
    "\n",
    "sns.barplot(x = mean_test_score_df.index, y = \"f1_macro\", data = mean_test_score_df, color='blue')\n",
    "# Add a title and labels to the plot\n",
    "plt.title('F1-macro Scores for Different Parameters')\n",
    "plt.xlabel('Combination')\n",
    "plt.ylabel('F1-macro Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_knn = pd.DataFrame(grid_search_knn.cv_results_)\n",
    "results_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a pivot table before create the heatmap\n",
    "scores_knn = results_knn.pivot(index='param_leaf_size', columns='param_n_neighbors', values='mean_test_score')\n",
    "scores_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(scores_knn, annot=True, cmap='viridis', fmt='.5g')\n",
    "plt.xlabel('param_n_neighbors')\n",
    "plt.ylabel('param_leaf_size')\n",
    "plt.title('Mean F1-score over all folds for each combination of parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4. Comments on the results for each on the intents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The aim of this analysis is to assess the predictive capability of two models in classifying attack labels. The models will be evaluated based on the hyperparameters identified previously.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation of Random Forest with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with the hyperparameters\n",
    "model_rf_tunned = RandomForestClassifier(n_estimators = 50, max_depth = 10000)\n",
    "\n",
    "st = time.time()\n",
    "# Trainning the model\n",
    "model_rf_tunned.fit(X_train, y_train_mlb)\n",
    "et = time.time()\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print(f'Time to train the model:', elapsed_time,'seconds','\\n')\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred_tune = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the test data\n",
    "accuracy = model_rf_tunned.score(X_test, y_test_mlb)\n",
    "print(f\"Accuracy of the 'Random Forest' model for test set: {accuracy:.2f}\",'\\n')\n",
    "\n",
    "# Evaluate performance on test set\n",
    "report_test_tune = classification_report(y_test_mlb, y_test_pred_tune, target_names=mlb.classes_, output_dict=True,\n",
    "                                         zero_division=1)\n",
    "df_report_test_tune = pd.DataFrame(report_test_tune).transpose()\n",
    "print(f'         Classification Report Trainning Set', '\\n')\n",
    "print(df_report_test_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(df_report_test_tune.loc[\"Defense Evasion\" : \"Persistence\"], cmap='Blues', annot=True, vmin=.0, vmax=1,fmt='.3f')\n",
    "plt.xlabel('Intents')\n",
    "plt.ylabel('Evaluation technique')\n",
    "plt.title('Intents classification report')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evalutaing of K-Nearest Neighbors with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the k-NN model\n",
    "knn_tune = KNeighborsClassifier(leaf_size=10, n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "t = time.time()\n",
    "knn_tune.fit(X_train, y_train_mlb)\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print(f\"Time to train the model: {elapsed_time} seconds\")\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions_knn_tune = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the test data\n",
    "accuracy_knn_tune = knn.score(X_test, y_test_mlb)\n",
    "print(f\"Accuracy of the k-NN model: {accuracy_knn_tune:.2f}\",'\\n')\n",
    "\n",
    "report_knn_tune = classification_report(y_test_mlb, predictions_knn_tune, target_names = mlb.classes_, output_dict=True,\n",
    "                                       zero_division=1)\n",
    "df_report_knn_tune = pd.DataFrame(report_knn_tune).transpose()\n",
    "print(\"              Classification Report for KNN\",'\\n')\n",
    "print(df_report_knn_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(df_report_knn_tune.loc[\"Defense Evasion\" : \"Persistence\"], cmap='Blues', annot=True, vmin=.0, vmax=1,fmt='.3f')\n",
    "plt.xlabel('Intents')\n",
    "plt.ylabel('Evaluation technique')\n",
    "plt.title('Classification report')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to write how the hyperparameter tunning improves the result; especially in the intent Impact, for both models... I'll do it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Explore the possible features: try combining features differently, e.g., does tf-idf improve or worsen performance? Think about the problem and summarize the ways you have tried (even those that did not work).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"><b>First Attempt</b></div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">For the first attempt, 33 features were used for the training set. The classifiers selected to perform the predictions were 'Random Forest' and 'K-Nearest Neighbor' with both models using the default parameters. In the performance evaluation, an accuracy of 98% was obtained for both models in the validation set.  While in the training set it reached 99% for RF and 98% for KNN. The decrease in accuracy achieved by RF in the validation set suggests a slight overfitting, however, it is a tolerable value that assumes that the model still performs well on the test set.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">According to the classification report, for almost all attempts the values of precision, recall and f1-scores reached high percentages, around 98.9%.  Except for the 'Impact' and 'Harmless' intents when applying RF as a model, the results obtained for these classes were quite lower compared to those obtained for the other classes, both in the training set and in the validation set, where 0% was obtained in each metric. The model presented a very poor performance when trying to classify these two classes.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">As for tuning techniques, K-fold cross-correlation and Grid Search were applied to see if the results obtained previously could be improved. However, when looking at the results obtained with 5 folds, the performance decreased considerably reaching an average of 77% accuracy. Suggests that the model may be in overfitting. </div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">Therefore, for the next attempt we consider a reduction of the dimensionality of the data set to improve generalization.</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"><b>Second attempt</b></div><br>\n",
    "<div style=\"text-align: justify\">For the second attempt, the number of features was reduced to only 12 for the training set.  The classifiers used in the previous attempt, RF and KNN, were kept for this evaluation with both using their default parameters. The results obtained in the performance evaluation, the accuracy did not change from the previous attempt, reaching 98% for the RF case and 98% for the KNN for both the training and validation sets, indicating that the models continue to make good predictions for the classes.<br>\n",
    "<br>\n",
    "<div style=\"text-align: justify\">If we take a look at the classification report for almost all attempts, the values for accuracy, recall and f1-scores reached high percentages, around 98%. Nevertheless, the performance of the 'Impact' class was very poor in both models for the classification obtained in the validation data, with 0% for every metric (precision, recall and f1-score), indicating that the number of features selected to train both models was not sufficient to be able to correctly classify this class.<br><br>\n",
    "<div style=\"text-align: justify\">In both training and validation reports, the F1 score obtained for the classes \"Impact\" and \"Harmless\" was very low compared to the other classes. It seems that for both models, these two classes are the most difficult to classify correctly. This could be due to the fact that, the number of data selected during the splitting of the training set did not cover enough samples of these two classes, as they are the least sampled attempts of the whole dataset. </div><br>\n",
    "\n",
    "<div style=\"text-align: justify\">After conducting multiple tests and adjusting the number of features in the training set, the results showed similar levels of accuracy. However, upon further analysis of the classification report parameters, it was found that the highest metrics for accuracy, recall, and F1-score were achieved with a number of features greater than 22. The F1-score parameter indicated that the models performed better in classifying samples belonging to the 'Impact' and 'Harmless' classes, which were more difficult to detect in almost all the tests. </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from preprocessing import clean_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<left><b><font size=4>Section 1 â€“ Data exploration and pre-processing<b><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of all the SSH sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_parquet('ssh_attacks.parquet')\n",
    "df=df_original.copy()\n",
    "df['first_timestamp'] = pd.to_datetime(df['first_timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. When are the attacks performed? Analyze the temporal series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame containing only attack instances\n",
    "# Excluding sessions labeled as \"Harmless\" with a single label\n",
    "df_attacks = df.loc[~df[\"Set_Fingerprint\"].apply(lambda x : \"Harmless\" in x and len(x) == 1)]\n",
    "attacks_per_day = df_attacks['first_timestamp'].dt.date.value_counts().sort_index().to_frame(\"Number_of_attacks_per_day\")\n",
    "attacks_per_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of attack occurrences based on the temporal series of first_timestamp showcases a trend in attack frequency over time.\n",
    "The dataset has been transformed to interpret the first_timestamp column as datetime objects for accurate temporal analysis. The subsequent process isolates attack instances within the dataset, excluding records tagged as \"Harmless\" with a single label.\n",
    "The resulting analysis presents the number of attacks per day:\n",
    "\n",
    "| Date_time | Attacks |\n",
    "| --- | --- |\n",
    "|June 4th, 2019 | 82 attacks |\n",
    "|June 5th, 2019 | 124 attacks |\n",
    "|June 6th, 2019 | 117 attacks |\n",
    "|June 7th, 2019 | 121 attacks |\n",
    "|June 8th, 2019 | 118 attacks |\n",
    "| ... (continues with dates up to) |\n",
    "| February 25th, 2020| 649 attacks |\n",
    "| February 26th, 2020| 483 attacks |\n",
    "| February 27th, 2020| 551 attacks |\n",
    "| February 28th, 2020| 580 attacks |\n",
    "| February 29th, 2020| 627 attacks |\n",
    "\n",
    "This temporal series reveals fluctuations in attack intensity over time, with notable spikes and drops in attack occurrences. The observations suggest potential patterns or trends that could be further explored to understand the dynamics of these SSH shell attacks across different periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = attacks_per_day,\n",
    "    linestyle='-',\n",
    "    color= 'blue',\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.title('Number of Attacks')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of attacks\")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%y'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization depicting attack frequencies over time reveals distinct patterns:\n",
    "\n",
    "Between June 2019 and September 2019, there is a conspicuous decrease in attack occurrences, indicating a phase of minimal activity. Subsequently, there is a significant surge in attack instances towards the latter part of 2019, signifying a notable rise in both the frequency and intensity of attacks during this period.\n",
    "\n",
    "This timeline underscores a stark contrast between the relatively quiet phase observed from June to September 2019 and the pronounced escalation in attack activities, particularly notable in the latter months of the year. This shift in trend emphasizes a substantial alteration in attack behavior, marked by an extended period of low activity succeeded by a considerable surge in attack incidents towards the year's end.\n",
    "\n",
    "Moreover, at the beginning of 2020, there is a noticeable decline in attack occurrences once more. This decline follows the heightened activity observed in late 2019, representing a shift from the increased attack rates back to a decreased frequency as the year transitions into its initial months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks_per_year = df_attacks.groupby(df['first_timestamp'].dt.year).size().to_frame(\"Number_attacks\").reset_index()\n",
    "attacks_per_year.rename(columns={\"first_timestamp\": \"Year\"}, inplace=True)\n",
    "attacks_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contrast in attack counts between the two years, with 2019 showing a significantly higher number of attacks compared to 2020, can be reasonably attributed to the limited temporal coverage of the dataset for the year 2020. With data available for only two months of 2020, the reduced number of observations in this period is expected and explains the lower count of attacks for that year compared to the extensive records available for 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(\n",
    "    data = attacks_per_year,\n",
    "    x = \"Year\",\n",
    "    y = \"Number_attacks\",\n",
    "    hue= \"Year\",\n",
    "    palette = ['blue','orange']\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Number of attacks\")\n",
    "plt.title(\"Number of total attacks in 2019 and 2020\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks_2019 = df_attacks.loc[df_attacks[\"first_timestamp\"].dt.year == 2019]\n",
    "df_attacks_2019_month = df_attacks_2019.groupby(df_attacks_2019[\"first_timestamp\"].dt.month).size().to_frame(\"Number_attacks_2019_month\").reset_index()\n",
    "\n",
    "df_attacks_2020 = df_attacks.loc[df_attacks[\"first_timestamp\"].dt.year == 2020]\n",
    "df_attacks_2020_month = df_attacks_2020.groupby(df_attacks_2020[\"first_timestamp\"].dt.month).size().to_frame(\"Number_attacks_2020_month\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1,2 ,sharey=True)\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(\n",
    "    data = df_attacks_2019_month,\n",
    "    x = \"first_timestamp\",\n",
    "    y = \"Number_attacks_2019_month\",\n",
    "    ax=axes[0],\n",
    "    color = 'blue'  \n",
    ")\n",
    "plt.title(\"2019\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of attacks\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(\n",
    "    data = df_attacks_2020_month,\n",
    "    x = \"first_timestamp\",\n",
    "    y = \"Number_attacks_2020_month\",\n",
    "    ax=axes[1],\n",
    "    color = 'orange'\n",
    ")\n",
    "plt.title(\"2020\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of attacks\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar charts reveal intriguing trends:\n",
    "\n",
    "- In 2019, there is a noticeable surge in the number of attacks from months 9 to 12. A progressive increase in attack activity is observed during these months, reaching a peak towards the year's end.\n",
    "\n",
    "- At the onset of 2020, in months 1 and 2, a relatively similar frequency of attacks is noted, approximately representing half the number of attacks compared to month 10 in 2019.\n",
    "\n",
    "These patterns outline a significant uptick in attack activity towards the end of 2019, followed by a comparatively steady beginning in 2020 with a considerably lower number of attacks compared to the peak period of the previous year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. Extract features from the attack sessions. How does the empirical distribution of the number of\n",
    "characters in each session look like? How is the distribution of the number of word per session?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of characters and words in each session\n",
    "number_characters = df['full_session'].apply(lambda x: len([char for char in x if char.isalpha()]))\n",
    "\n",
    "number_words = df['full_session'].apply(lambda x: len(clean_session(x)))\n",
    "\n",
    "data = {\"number_characters\": number_characters, \"number_words\": number_words}\n",
    "df_number_characters_words = pd.DataFrame(data = data)\n",
    "df_number_characters_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.ecdfplot(\n",
    "    data = df_number_characters_words['number_characters'],\n",
    "    log_scale=True\n",
    ")\n",
    "plt.title(\"ECDF for characters\")\n",
    "plt.xlabel(\"Number of characters\")\n",
    "plt.ylabel(\"CDF\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.ecdfplot(\n",
    "    data = df_number_characters_words['number_words'],\n",
    "    log_scale=True\n",
    ")\n",
    "plt.title(\"ECDF for words\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.ylabel(\"CDF\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, it's possible to see that the distribution of words per session and the distribution of characters per session predominantly concentrate below 2000 words and below 20,000 characters, respectively.\n",
    "\n",
    "To have a clearer idea of the distribution, we decided to limit the x-axis for both plots so that we can closely examine these two distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histograms, it is observed that the distribution of character counts per session centers is concentrated around approximately 350 characters.\n",
    "Moreover, regarding the number of words per session, the distribution frequently peaks around 40 to 48 words. This indicates that sessions often contain this range of word counts, emphasizing a typical occurrence of sessions with this word count range. These insights provide a clear understanding of the common lengths observed within the attack sessions, both in terms of characters and words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3. What are the most common words in the sessions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all text from 'full_session' into a single string\n",
    "full_session = ' '.join(df['full_session'])\n",
    "session_cleaned = clean_session(full_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common_words = pd.Series(session_cleaned).value_counts().head(10)\n",
    "most_common_word = df_most_common_words.idxmax()\n",
    "frequency = df_most_common_words.max()\n",
    "word_freq=df_most_common_words.to_dict()\n",
    "most_common_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common word is : 'tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that holds the frequencies of the top 10 most common words\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This representation emphasizes words based on their frequency in the sessions. Words that appear more frequently will be displayed larger and more prominently within the WordCloud. The interpolation='bilinear' argument enhances the image quality for better clarity. The plt.axis('off') command removes the axis for a cleaner visual appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4. How are the intents distributed? How many intents per session do you observe? What are the most common intents? How are the intents distributed in time?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_df = df[[\"session_id\", \"first_timestamp\", \"Set_Fingerprint\"]]\n",
    "\n",
    "# Expanding the 'Set_Fingerprint' column to individual intents and sessions\n",
    "intents_df_exploted = intents_df.explode('Set_Fingerprint')\n",
    "intents_df_grouped = intents_df_exploted.groupby(\"session_id\").size().to_frame(\"Number_of_intents\")\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.ecdfplot(\n",
    "    data = intents_df_grouped,\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"ECDF for intents\")\n",
    "plt.xlabel(\"Intents\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = intents_df_exploted.groupby('Set_Fingerprint').size().sort_values(ascending=False).to_frame(\"Number_of_sessions\")\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.barplot(intents, x=\"Number_of_sessions\", y=intents.index, color=\"blue\", hue_order=intents.index)\n",
    "plt.title('Distribution of Intents')\n",
    "plt.xlabel('Number of sessions')\n",
    "plt.ylabel('Type of Intents')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presented bar chart shows the most common intentions found in the dataset; Discovery, Persistence and Execution lead the most used type of attacks for each of the sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intents_distribution = intents_df_exploted.groupby([pd.Grouper(key='first_timestamp', freq='D'), 'Set_Fingerprint']).size().to_frame(\"Number_of_intents\").reset_index()\n",
    "df_intents_distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data = df_intents_distribution,\n",
    "    x = \"first_timestamp\",\n",
    "    y = \"Number_of_intents\",\n",
    "    hue=\"Set_Fingerprint\",\n",
    "    legend=True\n",
    ")\n",
    "plt.title(\"Distribution of the intents over the time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of the intents\")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%y'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME WHICH PLOT SHOULD WE USE ?\n",
    "\n",
    "grid = sns.FacetGrid(df_intents_distribution, col=\"Set_Fingerprint\", col_wrap=1, height=4, sharey=False, aspect=2)\n",
    "\n",
    "grid.map(sns.lineplot, \"first_timestamp\", \"Number_of_intents\")\n",
    "\n",
    "grid.set_axis_labels(\"Date\", \"Number of Intents\")\n",
    "grid.set_titles(col_template=\"{col_name}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of intents unfolds as follows:\n",
    "\n",
    "**Defense Evasion**:\n",
    "No significant peaks noticed, with a few attacks observed between July and September 2019, remaining consistently low alongside 'Harmless', 'Impact', and 'Other' intents.\n",
    "\n",
    "**Execution**:\n",
    "Displays a sharp peak towards the end of 2019, notably in the last two months.\n",
    "\n",
    "**Persistence and Discovery**:\n",
    "Showcase an intriguing trend, reaching their highest peaks towards the end of 2019. These intents exhibit the highest frequency, notably surging towards the year-end, reaching maximum levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5. How can text represented numerically? Try to convert the text into numerical representations\n",
    "(vectors) through Bag of Words (BoW)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "\n",
    "A vocabulary of known words.\n",
    "A measure of the presence of known words.\n",
    "It is called a bag-of-words , because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_cleaned = df.copy()\n",
    "df_session_cleaned[\"full_session\"] = df_session_cleaned[\"full_session\"].apply(lambda x: clean_session(x))\n",
    "df_session_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df = 0.05)\n",
    "bow = count_vectorizer.fit_transform(df_session_cleaned[\"full_session\"].apply(lambda x : \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_cleaned_bow = pd.DataFrame(bow.toarray(), index=df_session_cleaned.index, columns = list(count_vectorizer.vocabulary_.keys()))\n",
    "for feature in df_session_cleaned_bow.columns:\n",
    "    df_session_cleaned_bow[feature] = normalize(df_session_cleaned_bow[feature].values.reshape(-1,1), norm=\"l2\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_cleaned_bow = pd.concat([df_session_cleaned, df_session_cleaned_bow], axis=1)\n",
    "df_session_cleaned_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6. Associate each word in each attack session with its TF-IDF value (Term Frequency-Inverse Document Frequency)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 0.05)\n",
    "tfid = tfidf_vectorizer.fit_transform(df_session_cleaned[\"full_session\"].apply(lambda x : \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_cleaned_tfidf = pd.DataFrame(tfid.toarray(), index=df_session_cleaned.index, columns = list(tfidf_vectorizer.vocabulary_.keys()))\n",
    "df_session_cleaned_tfidf = pd.concat([df_session_cleaned, df_session_cleaned_tfidf], axis=1)\n",
    "df_session_cleaned_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Correlation Matrix</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_bow = df_session_cleaned_bow.drop(columns=[\"session_id\", \"full_session\", \"first_timestamp\", \"Set_Fingerprint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_bow = df_features_bow.corr().abs()\n",
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(correlation_matrix_bow, cmap='Blues', annot=True, vmin=.0, vmax=1, cbar_kws={'label':'Correlation'})\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_tfidf = df_session_cleaned_tfidf.drop(columns=[\"session_id\", \"full_session\", \"first_timestamp\", \"Set_Fingerprint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_tfidf = df_features_tfidf.corr().abs()\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "sns.heatmap(correlation_matrix_tfidf, cmap='Blues', annot=True, vmin=.0, vmax=1, cbar_kws={'label':'Correlation'})\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_bow = PCA()\n",
    "pca_bow.fit(df_features_bow)\n",
    "explained_variance_bow = pca_bow.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(\n",
    "    data = explained_variance_bow,\n",
    "    marker = \"o\",\n",
    "    color = 'blue'\n",
    ")\n",
    "# Set up Seaborn style\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.xticks(range(0, len(explained_variance_bow), 5))\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Explained variance\")\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_bow = PCA(n_components=4)\n",
    "pca_result_bow = pca_bow.fit_transform(df_features_bow)\n",
    "pca_result_bow = pd.DataFrame(pca_result_bow, columns=[f'PC{i}' for i in range(pca_bow.n_components_)])\n",
    "pca_result_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tfidf = PCA()\n",
    "pca_tfidf.fit(df_features_tfidf)\n",
    "explained_variance_tfidf = pca_tfidf.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.lineplot(\n",
    "    data = explained_variance_tfidf,\n",
    "    marker=\"o\",\n",
    "    color = 'blue'\n",
    ")\n",
    "# Set up Seaborn style\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.xticks(range(0, len(explained_variance_tfidf), 5))\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Explained variance\")\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tfidf = PCA(n_components=3)\n",
    "pca_result_tfidf = pca_tfidf.fit_transform(df_features_tfidf)\n",
    "pca_result_tfidf = pd.DataFrame(pca_result_tfidf, columns=[f'PC{i}' for i in range(pca_tfidf.n_components_)])\n",
    "pca_result_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
